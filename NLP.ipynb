{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMElPbAbnUS11T+MUxJdyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshu0518/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regex\n",
        "Regular expression matching"
      ],
      "metadata": {
        "id": "xGnankgOr90A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr4HjYW_TGhF"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = 'Hi,My name is Himanshu singh from UP . My Mobile No is 8188937945 . Elon musk is world richest person having worth of 40 million dollors His CFO No is (848)-2345-587 '\n",
        "pattern = '\\(\\d{3}\\)-\\d{4}-\\d{3} |\\d{10}'\n",
        "re.findall(pattern,texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7y8ABDFVb6O",
        "outputId": "8e170a80-ddc7-4938-bdd2-788968788645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['8188937945', '(848)-2345-587 ']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = 'The gross cost of operating lease vehicles in FY2021 Q1 was $4.85 . Tesla employee count is 5400 . In previous quarter i.e. FY2020 Q4 it was $3 billion . FY2030 Q5'"
      ],
      "metadata": {
        "id": "OiqllChaV1wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '\\$[\\0-9\\.]+'\n",
        "re.findall(pattern,texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cf63PUbpzgE",
        "outputId": "56899278-12c4-499c-cc62-0a00f30a2a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$4.85 . ', '$3 ']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If I do ' want this $ sign i.e capturing groups\n",
        "pattern = '\\$([\\0-9\\.]+)'\n",
        "re.findall(pattern,texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijfym-D_rj0I",
        "outputId": "7b8118ee-750b-451f-d5d8-1980f3f0de88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4.85 . ', '3 ']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FY2021Q1 ==> 4.85   FY2020Q2 ==> 3\n",
        "pattern = '(FY\\d{4} Q[1234])[^\\$]+(\\$[0-9\\.]+)'\n",
        "re.findall(pattern,texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzb0Wt2Qr5F5",
        "outputId": "04bb4fc3-34a1-4dd2-fc16-5a9b18bf19a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('FY2021 Q1', '$4.85'), ('FY2020 Q4', '$3')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Extract all twitter handles from following text. Twitter handle is the text that appears after https://twitter.com/ and is a single word. Also it contains only alpha numeric characters i.e. A-Z a-z , o to 9 and underscore _"
      ],
      "metadata": {
        "id": "fTgnE9w2xnEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Follow our leader Elon musk on twitter here: https://twitter.com/elonmusk, more information\n",
        "on Tesla's products can be found at https://www.tesla.com/. Also here are leading influencers\n",
        "for tesla related news,\n",
        "https://twitter.com/teslarati\n",
        "https://twitter.com/dummy_tesla\n",
        "https://twitter.com/dummy_2_tesla\n",
        "'''\n",
        "pattern = 'https:\\/\\/twitter.com\\/([a-zA-z0-9_]+)' # todo: type your regex here\n",
        "\n",
        "re.findall(pattern, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqU4dGMEvKEi",
        "outputId": "4a4c3bb9-c4b9-4960-da6b-4ee6f2913fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elonmusk', 'teslarati', 'dummy_tesla', 'dummy_2_tesla']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "5h2CwRTboo5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"The Param Vir Chakra (PVC) is India's highest military decoration awarded for displaying distinguished acts of valor during wartime. Established on January 26, 1950, the medal is awarded to members of the Indian Armed Forces for their extraordinary bravery in the face of the enemy. The decoration is conferred for the most conspicuous bravery or some daring or pre-eminent act of valor or self-sacrifice, in the presence of the enemy, whether on land, at sea, or in the air.\""
      ],
      "metadata": {
        "id": "RN8LlU1FxqeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "LeKYnp3WpOdf",
        "outputId": "dc40bedd-c672-44d8-c78e-0ee68115f054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Param Vir Chakra (PVC) is India's highest military decoration awarded for displaying distinguished acts of valor during wartime. Established on January 26, 1950, the medal is awarded to members of the Indian Armed Forces for their extraordinary bravery in the face of the enemy. The decoration is conferred for the most conspicuous bravery or some daring or pre-eminent act of valor or self-sacrifice, in the presence of the enemy, whether on land, at sea, or in the air.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z15r1lAJp_bk",
        "outputId": "86ba5a31-926f-497a-9b06-a5729c336249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "# paragraphs ---> sentences"
      ],
      "metadata": {
        "id": "vaEiNC9hpRpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "MHx-JY2Tpr7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_YsfQEqpx8c",
        "outputId": "85c24826-63e5-4a8b-cc70-c401de3a9528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# paragraph --> word or sentence --> word\n",
        "para = doc[0]+doc[1]\n",
        "words = word_tokenize(para)"
      ],
      "metadata": {
        "id": "4m2QBdPQqfZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjnGSizrHMd",
        "outputId": "44c0bc6d-e76d-432a-b942-590f8a060ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "KfJ11QHlrZIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "words1=tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "id": "QexZhDUWr-pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "Stemming is a natural language processing (NLP) technique used to reduce words to their base or root stem. The goal is to strip suffixes or prefixes from words, transforming them into their most basic form, known as the \"stem.\" This process helps in improving the performance of text analysis tasks like search, indexing, and information retrieval by treating different forms of a word (e.g., \"running,\" \"runner,\" \"ran\") as the same term."
      ],
      "metadata": {
        "id": "5FVv6Pdps6hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['eat','eating','eaten','put','putting','history']"
      ],
      "metadata": {
        "id": "AnOT3ZxvsME3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "7B8GHfZbs5Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Port Stemmer**"
      ],
      "metadata": {
        "id": "MRkSjnx3vAsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()\n",
        "for word in words:\n",
        "  print(word + \" --> \" + stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD74NDFbt5cO",
        "outputId": "e991ea1e-1a25-474d-e3ed-107dd6aa6191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eat --> eat\n",
            "eating --> eat\n",
            "eaten --> eaten\n",
            "put --> put\n",
            "putting --> put\n",
            "history --> histori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**regexStemming**"
      ],
      "metadata": {
        "id": "xEmqdG9Ovy6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "WFzx8tx3uPlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['eatable','eating','eaten','puts','putting','fairly']"
      ],
      "metadata": {
        "id": "lFMmsTsCvNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = RegexpStemmer('ing$|s$|able$|en$')\n",
        "for word in words:\n",
        "  print(word + \" --> \" + stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p733ES9mwFhE",
        "outputId": "a9b5f3c6-d3ec-42c6-d89c-b6f80c9d45e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eatable --> eat\n",
            "eating --> eat\n",
            "eaten --> eat\n",
            "puts --> put\n",
            "putting --> putt\n",
            "fairly --> fairly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**snowball stemming**"
      ],
      "metadata": {
        "id": "hNRllyZuwxWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "Snowstemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "vJvzTKDOwgIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \" --> \" + Snowstemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t9-LkQNxHpr",
        "outputId": "92a53911-da8e-4911-9a0e-b2ce6d97bea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eatable --> eatabl\n",
            "eating --> eat\n",
            "eaten --> eaten\n",
            "puts --> put\n",
            "putting --> put\n",
            "fairly --> fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lametization\n",
        "(NLP) technique used to reduce words to their base or dictionary form, known as a \"lemma.\" Unlike stemming, which often removes prefixes or suffixes without considering the context, lemmatization uses morphological analysis and vocabulary to accurately identify the intended meaning and root form of a word."
      ],
      "metadata": {
        "id": "2Hd-vTQHyATY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "iQ_JlHYkxMLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y41XQT5tOB1o",
        "outputId": "65c1a5c4-e0ac-49ea-c724-bc8b2c688853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pos - Noun-n(default)\n",
        "2. Verb-v\n",
        "3. adjective -a\n",
        "4. adverb -r"
      ],
      "metadata": {
        "id": "26NwbBULOU7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer.lemmatize('running',pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8RGH7nmCNwZo",
        "outputId": "a2851aa2-ef26-49e5-b6b4-869f28db8596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \" --> \" + lemmatizer.lemmatize(word,pos = 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnK9i-rUN9VZ",
        "outputId": "7ebcca07-24d9-454e-ad40-218a617f912c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eat --> eat\n",
            "eating --> eat\n",
            "eaten --> eat\n",
            "put --> put\n",
            "putting --> put\n",
            "history --> history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Determinnig Pos**\n",
        "\n",
        "pos --> parts of speech tag"
      ],
      "metadata": {
        "id": "_b8At9Oxb6cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HR92ygFcx39",
        "outputId": "10a42946-9649-411f-dbea-eb082a0da1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "# pos_tag will create a list of words into  list of tupples having (word,pos)\n",
        "words = 'Ganga is our holy river'\n",
        "word_list = words.split()\n",
        "pos_tag(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjRUBwbgb5z4",
        "outputId": "48cdb176-3047-46f5-ab70-466dfe429853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ganga', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('our', 'PRP$'),\n",
              " ('holy', 'JJ'),\n",
              " ('river', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stopwords"
      ],
      "metadata": {
        "id": "JTCua2dRPofl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ic6YfrsFO__c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "XZZg5afKP3BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rBc9nKdP7fr",
        "outputId": "d6019703-8d5c-4cef-e0da-c05468a54685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqT7Nr_AQd5X",
        "outputId": "f0ec6d08-0ea6-4197-c268-74f1bac0bb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"The Param Vir Chakra (PVC) is India's highest military decoration awarded for displaying distinguished acts of valor during wartime. Established on January 26, 1950, the medal is awarded to members of the Indian Armed Forces for their extraordinary bravery in the face of the enemy. The decoration is conferred for the most conspicuous bravery or some daring or pre-eminent act of valor or self-sacrifice, in the presence of the enemy, whether on land, at sea, or in the air.\""
      ],
      "metadata": {
        "id": "1nA3S7T7QjSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "QjTBaOq7S5SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '[^a-zA-Z]'\n",
        "useless = re.findall(pattern,corpus)"
      ],
      "metadata": {
        "id": "axz4QWsSTAV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "2oNS6VJPWprq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "corpus = corpus.lower()\n",
        "for i in range(len(sentences)):\n",
        "  words = word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in useless and word not in stopwords.words('english') ]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "Vk8ilMDyQ9Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDY36It0Rxoa",
        "outputId": "ad72b6ad-2813-4a57-86a6-519d31924d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"the param vir chakra pvc india 's highest militari decor award display distinguish act valor wartim\",\n",
              " 'establish januari 26 1950 medal award member indian arm forc extraordinari braveri face enemi',\n",
              " 'the decor confer conspicu braveri dare pre-emin act valor self-sacrific presenc enemi whether land sea air']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "a5Ljrny5R0M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.lower()\n",
        "for i in range(len(sentences)):\n",
        "  words = word_tokenize(sentences[i])\n",
        "  words = [WordNetLemmatizer().lemmatize(word,pos='v') for word in words if word not in useless and word not in stopwords.words('english') ]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "UbSdTBaqZF8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV7MLAcUZTfR",
        "outputId": "820a0748-fe62-4ea8-ff78-7a1ca9a03b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"param vir chakra pvc india 's highest militari decor award display distinguish act valor wartim\",\n",
              " 'establish januari 26 1950 medal award member indian arm forc extraordinari braveri face enemi',\n",
              " 'decor confer conspicu braveri dare pre-emin act valor self-sacrific presenc enemi whether land sea air']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word2vec"
      ],
      "metadata": {
        "id": "rDMKjP1FRle2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-7Ng9x1ZnKa",
        "outputId": "37e67c4f-b0f8-4cab-d96f-5ca215e04946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec,KeyedVectors"
      ],
      "metadata": {
        "id": "SE4dv9dNaIgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "d0bHgnIMRj9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wv  = api.load('word2vec-google-news-300')\n",
        "vec_king = wv['king']"
      ],
      "metadata": {
        "id": "3IqoogbaScRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWzlVMO3Ss4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}